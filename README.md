# mini-llm-finetune

This project demonstrates fine-tuning a small GPT-2 language model on a tiny custom dataset using Hugging Face Transformers and PyTorch.

## What it does

- Loads GPT-2 and tokenizer  
- Fine-tunes on custom prompts and completions  
- Saves the fine-tuned model for downstream use  

## How to run

1. Install dependencies:

```bash
pip install -r requirements.txt
```

2. Run training:

```bash
python train.py
```

## Why it matters

This project showcases fundamental skills in:

- LLM fine-tuning  
- Data preparation for domain-specific tasks  
- Training pipelines with Hugging Face and PyTorch  

These skills are critical for AI research and applied machine learning roles.